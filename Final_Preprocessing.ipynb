{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ2qb_KJB6VJ",
        "outputId": "6770f1e0-97df-4f83-d557-f1eac99a0026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Processing train split for jaundice (160 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160/160 [00:20<00:00,  7.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing val split for jaundice (20 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:01<00:00, 16.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test split for jaundice (20 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:01<00:00, 15.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train split for normal (448 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 448/448 [01:00<00:00,  7.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing val split for normal (56 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56/56 [00:03<00:00, 16.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test split for normal (56 images)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56/56 [00:04<00:00, 12.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images processed and saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm # Progress Bar.\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for jaundice and normal images\n",
        "jaundice_path = \"/content/drive/MyDrive/Project 5: Jaundice Tracker/jaundice_dataset/jaundice/\"\n",
        "normal_path = \"/content/drive/MyDrive/Project 5: Jaundice Tracker/jaundice_dataset/normal/\"\n",
        "output_dir = \"/content/drive/MyDrive/Project 5: Jaundice Tracker/jaundice_dataset/jaundice_preprocessed/\"\n",
        "jaundice_images = os.listdir(jaundice_path)\n",
        "target_size = (224, 224) # Resizing images\n",
        "\n",
        "# Create output directories\n",
        "for split in[\"train\", \"val\", \"test\"]:\n",
        "  for category in[\"jaundice\", \"normal\"]:\n",
        "    os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
        "\n",
        "# Define dataset split ratios\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Preprocessing Function\n",
        "def preprocess_image(image_path, target_size=(224,224), augment=False):\n",
        "\n",
        "  # Load the image\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
        "\n",
        "  if augment:\n",
        "    # Apply random rotation (-10 to 10 degrees)\n",
        "    angle = random.uniform(-10, 10)\n",
        "    h, w = image.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
        "    image = cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "    # Apply horizontal flipping with 50 % probability\n",
        "    if random.random() > 0.5:\n",
        "      image = cv2.flip(image, 1)\n",
        "\n",
        "    # Apply brightness adjustment (random factor between 0.9 and 1.1)\n",
        "    factor = random.uniform(0.9, 1.1)\n",
        "    image = np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "  # Convert to YCrCb, LAB, and HSV Color Spaces\n",
        "  ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
        "  lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
        "  hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "  # Extract Cr (red chrominance), B (blue-yellow), and H (hue) channels\n",
        "  cr_channel = ycrcb[:,:, 2]\n",
        "  b_channel = lab[:,:,2]\n",
        "  h_channel = hsv[:,:,0]\n",
        "\n",
        "  # Apply CLAHE for contrast enahncement\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "  cr_channel = clahe.apply(cr_channel)\n",
        "  b_channel = clahe.apply(b_channel)\n",
        "\n",
        "  # Apply Otsu's Thresholding to Cr channel\n",
        "  _, cr_thresh = cv2.threshold(cr_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "  # Resize channels\n",
        "  image = cv2.resize(image, target_size).astype(np.float32)\n",
        "  cr_channel = cv2.resize(cr_channel, target_size).astype(np.float32)\n",
        "  b_channel = cv2.resize(b_channel, target_size).astype(np.float32)\n",
        "  h_channel = cv2.resize(h_channel, target_size).astype(np.float32)\n",
        "  cr_thresh = cv2.resize(cr_thresh, target_size).astype(np.float32)\n",
        "\n",
        "  # Standardize(mean subtraction) channels\n",
        "  epsilon = 1e-8\n",
        "  cr_channel = (cr_channel - np.mean(cr_channel)) / (np.std(cr_channel) + epsilon)\n",
        "  b_channel = (b_channel - np.mean(b_channel)) / (np.std(b_channel) + epsilon)\n",
        "  h_channel = (h_channel - np.mean(h_channel)) / (np.std(h_channel) + epsilon)\n",
        "\n",
        "  # Normalize binary mask (Cr theshold)\n",
        "  cr_thresh = cr_thresh / 255.0\n",
        "\n",
        "  # Normalize image\n",
        "  image = image / 255.0\n",
        "\n",
        "  # Expand dimensions to match shape (224, 224, 1)\n",
        "  cr_channel = np.expand_dims(cr_channel, axis=-1)\n",
        "  b_channel = np.expand_dims(b_channel, axis=-1)\n",
        "  h_channel = np.expand_dims(h_channel, axis=-1)\n",
        "  cr_thresh = np.expand_dims(cr_thresh, axis=-1)\n",
        "\n",
        "  # Concatenate channels RGB + extra channels\n",
        "  processed_image = np.concatenate([image, cr_channel, b_channel, h_channel, cr_thresh], axis=-1)\n",
        "\n",
        "\n",
        "  return image\n",
        "\n",
        "def split_and_preprocess(category, category_path):\n",
        "  image_paths = [os.path.join(category_path, img) for img in os.listdir(category_path)]\n",
        "  random.shuffle(image_paths)\n",
        "\n",
        "  train_idx = int(len(image_paths) * train_ratio)\n",
        "  val_idx = int(len(image_paths) * (train_ratio + val_ratio))\n",
        "\n",
        "  split_dict = {\n",
        "      \"train\": image_paths[:train_idx],\n",
        "      \"val\": image_paths[train_idx:val_idx],\n",
        "      \"test\": image_paths[val_idx:]\n",
        "  }\n",
        "\n",
        "  for split, paths in split_dict.items():\n",
        "    print(f\"Processing {split} split for {category} ({len(paths)} images)...\")\n",
        "    for img_path in tqdm(paths):\n",
        "      processed_image = preprocess_image(img_path, augment=(split == \"train\"))\n",
        "\n",
        "      if processed_image is not None:\n",
        "        save_path = os.path.join(output_dir, split, category, os.path.basename(img_path))\n",
        "        processed_image_bgr = cv2.cvtColor((processed_image * 255.0).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "        cv2.imwrite(save_path,processed_image_bgr)\n",
        "\n",
        "# Process jaundice and normal images\n",
        "split_and_preprocess(\"jaundice\", jaundice_path)\n",
        "split_and_preprocess(\"normal\", normal_path)\n",
        "\n",
        "print(\"All images processed and saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample Image from Dataset\n",
        "sample_image_path = os.path.join(jaundice_path, jaundice_images[9])\n",
        "\n",
        "# Load Original Image\n",
        "original_image = cv2.imread(sample_image_path)\n",
        "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Process one image\n",
        "processed_image = preprocess_image(sample_image_path)\n",
        "\n",
        "# Ensure correct scaling for grayscale\n",
        "cr_channel = processed_image[:, :, 3]\n",
        "b_channel = processed_image[:, :, 4]\n",
        "h_channel = processed_image[:, :, 5]\n",
        "cr_thresh = processed_image[:, :, 6]\n",
        "processed_image_display = (processed_image[:,:,3] * 255.0).astype(np.uint8)\n",
        "\n",
        "\n",
        "# Plot Original, Cr channel, B channel, H channel, and Processed Image\n",
        "plt.figure(figsize=(18,10))\n",
        "\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(original_image)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,3,2)\n",
        "plt.imshow(cr_channel, cmap=\"gray\")\n",
        "plt.title(\"Cr Channel (Red Chrominance)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,3,3)\n",
        "plt.imshow(b_channel, cmap=\"gray\")\n",
        "plt.title(\"B Channel (Blue-Yellow)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,3,4)\n",
        "plt.imshow(h_channel, cmap=\"gray\")\n",
        "plt.title(\"Hue Channel\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,3,5)\n",
        "plt.imshow(cr_thresh, cmap=\"gray\")\n",
        "plt.title(\"Cr Channel (Threshold)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "plt.imshow(processed_image_display)\n",
        "plt.title(\"Processed Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "khkiz_EdCERn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4326289b-97f2-4b6d-e9d8-541e28a64f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 3 is out of bounds for axis 2 with size 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cccaea110582>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Ensure correct scaling for grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcr_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mb_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mh_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
          ]
        }
      ]
    }
  ]
}